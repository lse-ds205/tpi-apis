{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASCOR database creation \n",
    "\n",
    "This notebook creates the SQL database for the ASCOR data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import pandas as pd \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Add the project root to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Now import with full module path\n",
    "from utils.database_creation_utils import get_db_connection, get_engine\n",
    "\n",
    "engine = get_engine(db_name=\"ascor_api\")\n",
    "session = get_db_connection(db_name=\"ascor_api\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Country Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_countries.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop and create the country table\n",
    "create_country_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS country;\n",
    "\n",
    "CREATE TABLE country (\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  iso VARCHAR,\n",
    "  region VARCHAR,\n",
    "  bank_lending_group VARCHAR,\n",
    "  imf_category VARCHAR,\n",
    "  un_party_type VARCHAR,\n",
    "  PRIMARY KEY (country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_country_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Select and rename columns to match database schema\n",
    "country_df = df[[\n",
    "    'Name',\n",
    "    'Country ISO code',\n",
    "    'Region',\n",
    "    'World Bank lending group',\n",
    "    'International Monetary Fund fiscal monitor category',\n",
    "    'Type of Party to the United Nations Framework Convention on Climate Change'\n",
    "]].copy()\n",
    "\n",
    "country_df.columns = [\n",
    "    'country_name', 'iso', 'region',\n",
    "    'bank_lending_group', 'imf_category', 'un_party_type'\n",
    "]\n",
    "\n",
    "# Insert into database\n",
    "country_df.to_sql(\"country\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Country table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Benchmark Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark tables created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_benchmarks.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Drop and create the benchmark tables\n",
    "create_benchmark_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS benchmark_values;\n",
    "DROP TABLE IF EXISTS benchmarks;\n",
    "\n",
    "CREATE TABLE benchmarks (\n",
    "  benchmark_id INT NOT NULL,\n",
    "  publication_date DATE NOT NULL,\n",
    "  emissions_metric VARCHAR NOT NULL,\n",
    "  emissions_boundary VARCHAR NOT NULL,\n",
    "  units VARCHAR NOT NULL,\n",
    "  benchmark_type VARCHAR NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (benchmark_id),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\n",
    "CREATE TABLE benchmark_values (\n",
    "  value FLOAT NOT NULL,\n",
    "  year INT NOT NULL,\n",
    "  benchmark_id INT NOT NULL,\n",
    "  PRIMARY KEY (benchmark_id, year),\n",
    "  FOREIGN KEY (benchmark_id) REFERENCES benchmarks(benchmark_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_benchmark_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Prepare the `benchmarks` DataFrame\n",
    "benchmarks_df = df[[\n",
    "    \"id\", \"publication_date\", \"emissions_metric\", \"emissions_boundary\",\n",
    "    \"units\", \"benchmark_type\", \"country\"\n",
    "]].copy()\n",
    "\n",
    "benchmarks_df.columns = [\n",
    "    \"benchmark_id\", \"publication_date\", \"emissions_metric\", \"emissions_boundary\",\n",
    "    \"units\", \"benchmark_type\", \"country_name\"\n",
    "]\n",
    "\n",
    "# Prepare the `benchmark_values` DataFrame\n",
    "value_columns = [col for col in df.columns if col.isdigit()]\n",
    "benchmark_values_df = df[['id'] + value_columns].melt(\n",
    "    id_vars='id',\n",
    "    var_name='year',\n",
    "    value_name='value'\n",
    ").dropna()\n",
    "\n",
    "benchmark_values_df.columns = ['benchmark_id', 'year', 'value']\n",
    "benchmark_values_df['year'] = benchmark_values_df['year'].astype(int)\n",
    "\n",
    "# Insert into the database\n",
    "benchmarks_df.to_sql(\"benchmarks\", engine, if_exists=\"append\", index=False)\n",
    "benchmark_values_df.to_sql(\"benchmark_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Benchmark tables created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment elements table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_indicators.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Select and rename columns to match database schema\n",
    "assessment_elements_df = df[[\n",
    "    'code', 'text', 'units_or_response_type', 'type'\n",
    "]].copy()\n",
    "\n",
    "assessment_elements_df.columns = ['code', 'text', 'response_type', 'type']\n",
    "assessment_elements_df['response_type'] = assessment_elements_df['response_type'].fillna(\"Not specified\")\n",
    "\n",
    "# Drop and create the assessment_elements table\n",
    "create_assessment_elements_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_elements;\n",
    "\n",
    "CREATE TABLE assessment_elements (\n",
    "  code VARCHAR NOT NULL,\n",
    "  text VARCHAR NOTL NUL,\n",
    "  response_type VARCHAR NOT NULL,\n",
    "  type VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (code)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_elements_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Insert into the database\n",
    "assessment_elements_df.to_sql(\"assessment_elements\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment elements table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Results Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/fkxp7dk132s2dqm5fccfhy9h0000gn/T/ipykernel_49747/1993979402.py:44: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  assessment_date = pd.to_datetime(row[\"Assessment date\"]).date()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment results table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the assessment results Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop and create the assessment_results table\n",
    "create_assessment_results_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_results;\n",
    "\n",
    "CREATE TABLE assessment_results (\n",
    "  assessment_id INT NOT NULL,\n",
    "  response VARCHAR,\n",
    "  assessment_date DATE,\n",
    "  publication_date DATE,\n",
    "  source VARCHAR,\n",
    "  year VARCHAR,\n",
    "  code VARCHAR NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (assessment_id, code),\n",
    "  FOREIGN KEY (code) REFERENCES assessment_elements(code),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_results_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Columns that represent coded responses (non-pillar only)\n",
    "response_cols = [col for col in df.columns if (\n",
    "    col.startswith(\"indicator \") or\n",
    "    col.startswith(\"metric \") or\n",
    "    col.startswith(\"area \")\n",
    ")]\n",
    "\n",
    "# Prepare a list for parsed results\n",
    "rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    assessment_id = row[\"Id\"]\n",
    "    country_name = row[\"Country\"]\n",
    "    assessment_date = pd.to_datetime(row[\"Assessment date\"]).date()\n",
    "    publication_date = pd.to_datetime(row[\"Publication date\"]).date()\n",
    "\n",
    "    for col in response_cols:\n",
    "        code = col.split(\" \", 1)[1]  # Extract e.g., \"EP.1.a\"\n",
    "        response = row[col] if pd.notna(row[col]) else None\n",
    "        original_col = col  # e.g., 'indicator EP.1.a'\n",
    "\n",
    "        # Look for optional year and source columns\n",
    "        year_col = f\"year {original_col}\"\n",
    "        year = str(int(row[year_col])) if year_col in df.columns and pd.notna(row[year_col]) else None\n",
    "\n",
    "        source_col = f\"source {original_col}\"\n",
    "        source = row[source_col] if source_col in df.columns and pd.notna(row[source_col]) else None\n",
    "\n",
    "        rows.append({\n",
    "            \"assessment_id\": assessment_id,\n",
    "            \"response\": response,\n",
    "            \"assessment_date\": assessment_date,\n",
    "            \"publication_date\": publication_date,\n",
    "            \"source\": source,\n",
    "            \"year\": year,\n",
    "            \"code\": code,\n",
    "            \"country_name\": country_name\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "assessment_results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Insert into the database\n",
    "assessment_results_df.to_sql(\"assessment_results\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment results table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Trends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment trends table created and populated successfully with composite primary key.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/fkxp7dk132s2dqm5fccfhy9h0000gn/T/ipykernel_49747/1832612965.py:20: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  assessment_trends_df[\"assessment_date\"] = pd.to_datetime(assessment_trends_df[\"assessment_date\"]).dt.date\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Select and rename relevant columns\n",
    "assessment_trends_df = df[[\n",
    "    'id', 'country', 'emissions_metric', 'emissions_boundary',\n",
    "    'units', 'assessment_date', 'publication_date', 'last_historical_year'\n",
    "]].copy()\n",
    "\n",
    "assessment_trends_df.columns = [\n",
    "    'trend_id', 'country_name', 'emissions_metric', 'emissions_boundary',\n",
    "    'units', 'assessment_date', 'publication_date', 'last_historical_year'\n",
    "]\n",
    "\n",
    "# Convert date and year fields to appropriate types\n",
    "assessment_trends_df[\"assessment_date\"] = pd.to_datetime(assessment_trends_df[\"assessment_date\"]).dt.date\n",
    "assessment_trends_df[\"publication_date\"] = pd.to_datetime(assessment_trends_df[\"publication_date\"]).dt.date\n",
    "assessment_trends_df[\"last_historical_year\"] = assessment_trends_df[\"last_historical_year\"].astype(\"Int64\")\n",
    "\n",
    "# SQL schema with composite primary key\n",
    "create_assessment_trends_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_trends;\n",
    "\n",
    "CREATE TABLE assessment_trends (\n",
    "  trend_id INT NOT NULL,\n",
    "  emissions_metric VARCHAR,\n",
    "  emissions_boundary VARCHAR,\n",
    "  units VARCHAR,\n",
    "  assessment_date DATE,\n",
    "  publication_date DATE,\n",
    "  last_historical_year INT,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (trend_id, country_name),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL and insert the data\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_trends_sql))\n",
    "    conn.commit()\n",
    "\n",
    "assessment_trends_df.to_sql(\"assessment_trends\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment trends table created and populated successfully with composite primary key.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend values table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedColumn) column \"metric_EP1_a_i\" of relation \"trend_values\" does not exist\nLINE 1: INSERT INTO trend_values (trend_id, country_name, \"metric_EP...\n                                                          ^\n\n[SQL: INSERT INTO trend_values (trend_id, country_name, \"metric_EP1_a_i\", \"source_metric_EP1_a_i\", \"year_metric_EP1_a_i\", \"metric_EP1_a_ii_1_year\", \"metric_EP1_a_ii_3_year\", \"metric_EP1_a_ii_5_year\") VALUES (%(trend_id__0)s, %(country_name__0)s, %(metric_E ... 195619 characters truncated ... , %(metric_EP1_a_ii_1_year__854)s, %(metric_EP1_a_ii_3_year__854)s, %(metric_EP1_a_ii_5_year__854)s)]\n[parameters: {'source_metric_EP1_a_i__0': None, 'metric_EP1_a_ii_1_year__0': \"'-11.20%\", 'metric_EP1_a_ii_5_year__0': \"'-7.00%\", 'metric_EP1_a_ii_3_year__0': \"'-8.20%\", 'country_name__0': 'Australia', 'year_metric_EP1_a_i__0': None, 'trend_id__0': 291, 'metric_EP1_a_i__0': '328.04', 'source_metric_EP1_a_i__1': None, 'metric_EP1_a_ii_1_year__1': \"'-0.60%\", 'metric_EP1_a_ii_5_year__1': \"'-2.10%\", 'metric_EP1_a_ii_3_year__1': \"'-2.20%\", 'country_name__1': 'Australia', 'year_metric_EP1_a_i__1': None, 'trend_id__1': 290, 'metric_EP1_a_i__1': '20.54', 'source_metric_EP1_a_i__2': None, 'metric_EP1_a_ii_1_year__2': '0.50%', 'metric_EP1_a_ii_5_year__2': \"'-1.00%\", 'metric_EP1_a_ii_3_year__2': \"'-1.40%\", 'country_name__2': 'Australia', 'year_metric_EP1_a_i__2': None, 'trend_id__2': 289, 'metric_EP1_a_i__2': '533.7', 'source_metric_EP1_a_i__3': None, 'metric_EP1_a_ii_1_year__3': '25.00%', 'metric_EP1_a_ii_5_year__3': '5.30%', 'metric_EP1_a_ii_3_year__3': '5.80%', 'country_name__3': 'Australia', 'year_metric_EP1_a_i__3': None, 'trend_id__3': 294, 'metric_EP1_a_i__3': '0.0', 'source_metric_EP1_a_i__4': None, 'metric_EP1_a_ii_1_year__4': '16.10%', 'metric_EP1_a_ii_5_year__4': '1.70%', 'metric_EP1_a_ii_3_year__4': '0.50%', 'country_name__4': 'Australia', 'year_metric_EP1_a_i__4': None, 'trend_id__4': 293, 'metric_EP1_a_i__4': '0.0', 'source_metric_EP1_a_i__5': None, 'metric_EP1_a_ii_1_year__5': '15.10%', 'metric_EP1_a_ii_5_year__5': '0.70%', 'metric_EP1_a_ii_3_year__5': \"'-0.30%\", 'country_name__5': 'Australia', 'year_metric_EP1_a_i__5': None, 'trend_id__5': 292, 'metric_EP1_a_i__5': '0.0', 'source_metric_EP1_a_i__6': None, 'metric_EP1_a_ii_1_year__6': \"'-4.20%\" ... 6740 parameters truncated ... 'trend_id__848': 1058, 'metric_EP1_a_i__848': '336.74', 'source_metric_EP1_a_i__849': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__849': '1.28%', 'metric_EP1_a_ii_5_year__849': '1.73%', 'metric_EP1_a_ii_3_year__849': '3.39%', 'country_name__849': 'Uruguay', 'year_metric_EP1_a_i__849': 2023, 'trend_id__849': 1059, 'metric_EP1_a_i__849': '11.47', 'source_metric_EP1_a_i__850': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__850': '0.24%', 'metric_EP1_a_ii_5_year__850': '0.27%', 'metric_EP1_a_ii_3_year__850': '0.38%', 'country_name__850': 'Uruguay', 'year_metric_EP1_a_i__850': 2023, 'trend_id__850': 1060, 'metric_EP1_a_i__850': '-1.69', 'source_metric_EP1_a_i__851': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__851': 'Not applicable', 'metric_EP1_a_ii_5_year__851': 'Not applicable', 'metric_EP1_a_ii_3_year__851': 'Not applicable', 'country_name__851': 'Uruguay', 'year_metric_EP1_a_i__851': 2023, 'trend_id__851': 1062, 'metric_EP1_a_i__851': '0.0', 'source_metric_EP1_a_i__852': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__852': 'Not applicable', 'metric_EP1_a_ii_5_year__852': 'Not applicable', 'metric_EP1_a_ii_3_year__852': 'Not applicable', 'country_name__852': 'Uruguay', 'year_metric_EP1_a_i__852': 2023, 'trend_id__852': 1061, 'metric_EP1_a_i__852': '0.0', 'source_metric_EP1_a_i__853': 'https://globalcarbonatlas.org/emissions/carbon-emissions/', 'metric_EP1_a_ii_1_year__853': '17.67%', 'metric_EP1_a_ii_5_year__853': '4.26%', 'metric_EP1_a_ii_3_year__853': '4.48%', 'country_name__853': 'Uruguay', 'year_metric_EP1_a_i__853': 2021, 'trend_id__853': 1054, 'metric_EP1_a_i__853': '12.03', 'source_metric_EP1_a_i__854': 'https://globalcarbonatlas.org/emissions/carbon-emissions/', 'metric_EP1_a_ii_1_year__854': '17.77%', 'metric_EP1_a_ii_5_year__854': '4.18%', 'metric_EP1_a_ii_3_year__854': '4.49%', 'country_name__854': 'Uruguay', 'year_metric_EP1_a_i__854': 2021, 'trend_id__854': 1056, 'metric_EP1_a_i__854': '3.51'}]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedColumn\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2116\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2116\u001b[39m         \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2121\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUndefinedColumn\u001b[39m: column \"metric_EP1_a_i\" of relation \"trend_values\" does not exist\nLINE 1: INSERT INTO trend_values (trend_id, country_name, \"metric_EP...\n                                                          ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     conn.execute(text(create_trend_values_sql))\n\u001b[32m     41\u001b[39m     conn.commit()\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrend_values_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrend_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrend values table created and populated successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/core/generic.py:3087\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2890\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:842\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:2018\u001b[39m, in \u001b[36mSQLDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   2006\u001b[39m sql_engine = get_engine(engine)\n\u001b[32m   2008\u001b[39m table = \u001b[38;5;28mself\u001b[39m.prep_table(\n\u001b[32m   2009\u001b[39m     frame=frame,\n\u001b[32m   2010\u001b[39m     name=name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2015\u001b[39m     dtype=dtype,\n\u001b[32m   2016\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2018\u001b[39m total_inserted = \u001b[43msql_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[38;5;28mself\u001b[39m.check_case_sensitive(name=name, schema=schema)\n\u001b[32m   2031\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:1567\u001b[39m, in \u001b[36mSQLAlchemyEngine.insert_records\u001b[39m\u001b[34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[39m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m re.search(msg, err_text):\n\u001b[32m   1566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minf cannot be used with MySQL\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:1558\u001b[39m, in \u001b[36mSQLAlchemyEngine.insert_records\u001b[39m\u001b[34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[39m\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[32m   1557\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.StatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1560\u001b[39m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[32m   1561\u001b[39m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[32m   1562\u001b[39m     msg = \u001b[33mr\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m(1054, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown column \u001b[39m\u001b[33m'\u001b[39m\u001b[33minf(e0)?\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfield list\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m))(?#\u001b[39m\n\u001b[32m   1563\u001b[39m \u001b[33m    )|inf can not be used with MySQL\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:1119\u001b[39m, in \u001b[36mSQLTable.insert\u001b[39m\u001b[34m(self, chunksize, method)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1118\u001b[39m chunk_iter = \u001b[38;5;28mzip\u001b[39m(*(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m num_inserted = \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/pandas/io/sql.py:1010\u001b[39m, in \u001b[36mSQLTable._execute_insert\u001b[39m\u001b[34m(self, conn, keys, data_iter)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    999\u001b[39m \u001b[33;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[32m   1000\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m \u001b[33;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[32m   1008\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1009\u001b[39m data = [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m result = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1418\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:515\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    514\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1640\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1628\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1629\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1630\u001b[39m )\n\u001b[32m   1632\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1633\u001b[39m     dialect=dialect,\n\u001b[32m   1634\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1638\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1639\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1640\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1654\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1655\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1659\u001b[39m         ret,\n\u001b[32m   1660\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1844\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m context.pre_exec()\n\u001b[32m   1843\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.execute_style \u001b[38;5;129;01mis\u001b[39;00m ExecuteStyle.INSERTMANYVALUES:\n\u001b[32m-> \u001b[39m\u001b[32m1844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_insertmany_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_single_context(\n\u001b[32m   1847\u001b[39m         dialect, context, statement, parameters\n\u001b[32m   1848\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2124\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2116\u001b[39m         dialect.do_execute(\n\u001b[32m   2117\u001b[39m             cursor,\n\u001b[32m   2118\u001b[39m             sub_stmt,\n\u001b[32m   2119\u001b[39m             sub_params,\n\u001b[32m   2120\u001b[39m             context,\n\u001b[32m   2121\u001b[39m         )\n\u001b[32m   2123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2124\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_long_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m        \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_sub_exec\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2131\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine_events:\n\u001b[32m   2134\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   2135\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2136\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2140\u001b[39m         context.executemany,\n\u001b[32m   2141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2353\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2351\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2352\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2353\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2354\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2355\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2116\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2114\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2116\u001b[39m         \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2121\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_dbapi_exception(\n\u001b[32m   2125\u001b[39m         e,\n\u001b[32m   2126\u001b[39m         sql_util._long_statement(sub_stmt),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2130\u001b[39m         is_sub_exec=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2131\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/tpi-apis/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.UndefinedColumn) column \"metric_EP1_a_i\" of relation \"trend_values\" does not exist\nLINE 1: INSERT INTO trend_values (trend_id, country_name, \"metric_EP...\n                                                          ^\n\n[SQL: INSERT INTO trend_values (trend_id, country_name, \"metric_EP1_a_i\", \"source_metric_EP1_a_i\", \"year_metric_EP1_a_i\", \"metric_EP1_a_ii_1_year\", \"metric_EP1_a_ii_3_year\", \"metric_EP1_a_ii_5_year\") VALUES (%(trend_id__0)s, %(country_name__0)s, %(metric_E ... 195619 characters truncated ... , %(metric_EP1_a_ii_1_year__854)s, %(metric_EP1_a_ii_3_year__854)s, %(metric_EP1_a_ii_5_year__854)s)]\n[parameters: {'source_metric_EP1_a_i__0': None, 'metric_EP1_a_ii_1_year__0': \"'-11.20%\", 'metric_EP1_a_ii_5_year__0': \"'-7.00%\", 'metric_EP1_a_ii_3_year__0': \"'-8.20%\", 'country_name__0': 'Australia', 'year_metric_EP1_a_i__0': None, 'trend_id__0': 291, 'metric_EP1_a_i__0': '328.04', 'source_metric_EP1_a_i__1': None, 'metric_EP1_a_ii_1_year__1': \"'-0.60%\", 'metric_EP1_a_ii_5_year__1': \"'-2.10%\", 'metric_EP1_a_ii_3_year__1': \"'-2.20%\", 'country_name__1': 'Australia', 'year_metric_EP1_a_i__1': None, 'trend_id__1': 290, 'metric_EP1_a_i__1': '20.54', 'source_metric_EP1_a_i__2': None, 'metric_EP1_a_ii_1_year__2': '0.50%', 'metric_EP1_a_ii_5_year__2': \"'-1.00%\", 'metric_EP1_a_ii_3_year__2': \"'-1.40%\", 'country_name__2': 'Australia', 'year_metric_EP1_a_i__2': None, 'trend_id__2': 289, 'metric_EP1_a_i__2': '533.7', 'source_metric_EP1_a_i__3': None, 'metric_EP1_a_ii_1_year__3': '25.00%', 'metric_EP1_a_ii_5_year__3': '5.30%', 'metric_EP1_a_ii_3_year__3': '5.80%', 'country_name__3': 'Australia', 'year_metric_EP1_a_i__3': None, 'trend_id__3': 294, 'metric_EP1_a_i__3': '0.0', 'source_metric_EP1_a_i__4': None, 'metric_EP1_a_ii_1_year__4': '16.10%', 'metric_EP1_a_ii_5_year__4': '1.70%', 'metric_EP1_a_ii_3_year__4': '0.50%', 'country_name__4': 'Australia', 'year_metric_EP1_a_i__4': None, 'trend_id__4': 293, 'metric_EP1_a_i__4': '0.0', 'source_metric_EP1_a_i__5': None, 'metric_EP1_a_ii_1_year__5': '15.10%', 'metric_EP1_a_ii_5_year__5': '0.70%', 'metric_EP1_a_ii_3_year__5': \"'-0.30%\", 'country_name__5': 'Australia', 'year_metric_EP1_a_i__5': None, 'trend_id__5': 292, 'metric_EP1_a_i__5': '0.0', 'source_metric_EP1_a_i__6': None, 'metric_EP1_a_ii_1_year__6': \"'-4.20%\" ... 6740 parameters truncated ... 'trend_id__848': 1058, 'metric_EP1_a_i__848': '336.74', 'source_metric_EP1_a_i__849': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__849': '1.28%', 'metric_EP1_a_ii_5_year__849': '1.73%', 'metric_EP1_a_ii_3_year__849': '3.39%', 'country_name__849': 'Uruguay', 'year_metric_EP1_a_i__849': 2023, 'trend_id__849': 1059, 'metric_EP1_a_i__849': '11.47', 'source_metric_EP1_a_i__850': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__850': '0.24%', 'metric_EP1_a_ii_5_year__850': '0.27%', 'metric_EP1_a_ii_3_year__850': '0.38%', 'country_name__850': 'Uruguay', 'year_metric_EP1_a_i__850': 2023, 'trend_id__850': 1060, 'metric_EP1_a_i__850': '-1.69', 'source_metric_EP1_a_i__851': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__851': 'Not applicable', 'metric_EP1_a_ii_5_year__851': 'Not applicable', 'metric_EP1_a_ii_3_year__851': 'Not applicable', 'country_name__851': 'Uruguay', 'year_metric_EP1_a_i__851': 2023, 'trend_id__851': 1062, 'metric_EP1_a_i__851': '0.0', 'source_metric_EP1_a_i__852': 'https://zenodo.org/records/13752654', 'metric_EP1_a_ii_1_year__852': 'Not applicable', 'metric_EP1_a_ii_5_year__852': 'Not applicable', 'metric_EP1_a_ii_3_year__852': 'Not applicable', 'country_name__852': 'Uruguay', 'year_metric_EP1_a_i__852': 2023, 'trend_id__852': 1061, 'metric_EP1_a_i__852': '0.0', 'source_metric_EP1_a_i__853': 'https://globalcarbonatlas.org/emissions/carbon-emissions/', 'metric_EP1_a_ii_1_year__853': '17.67%', 'metric_EP1_a_ii_5_year__853': '4.26%', 'metric_EP1_a_ii_3_year__853': '4.48%', 'country_name__853': 'Uruguay', 'year_metric_EP1_a_i__853': 2021, 'trend_id__853': 1054, 'metric_EP1_a_i__853': '12.03', 'source_metric_EP1_a_i__854': 'https://globalcarbonatlas.org/emissions/carbon-emissions/', 'metric_EP1_a_ii_1_year__854': '17.77%', 'metric_EP1_a_ii_5_year__854': '4.18%', 'metric_EP1_a_ii_3_year__854': '4.49%', 'country_name__854': 'Uruguay', 'year_metric_EP1_a_i__854': 2021, 'trend_id__854': 1056, 'metric_EP1_a_i__854': '3.51'}]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load and clean the Excel file\n",
    "trend_values_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "trend_values_data.columns = trend_values_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Extract and rename relevant columns\n",
    "trend_values_df = trend_values_data[[\n",
    "    \"id\", \"country\", \"metric_ep1.a.i\", \"source_metric_ep1.a.i\", \"year_metric_ep1.a.i\",\n",
    "    \"metric_ep1.a.ii_1-year\", \"metric_ep1.a.ii_3-year\", \"metric_ep1.a.ii_5-year\"\n",
    "]].copy()\n",
    "\n",
    "trend_values_df.columns = [\n",
    "    \"trend_id\", \"country_name\", \"metric_EP1_a_i\", \"source_metric_EP1_a_i\", \"year_metric_EP1_a_i\",\n",
    "    \"metric_EP1_a_ii_1_year\", \"metric_EP1_a_ii_3_year\", \"metric_EP1_a_ii_5_year\"\n",
    "]\n",
    "\n",
    "# Ensure year is integer-compatible where possible\n",
    "trend_values_df[\"year_metric_EP1_a_i\"] = pd.to_numeric(trend_values_df[\"year_metric_EP1_a_i\"], errors='coerce').astype(\"Int64\")\n",
    "\n",
    "# SQL: Create table with composite PK and nullable fields\n",
    "create_trend_values_sql = \"\"\"\n",
    "CREATE TABLE trend_values (\n",
    "  metric_ep1_a_i FLOAT,\n",
    "  source_metric_ep1_a_i VARCHAR,\n",
    "  year_metric_ep1_a_i INT,\n",
    "  metric_ep1_a_ii_1_year VARCHAR,\n",
    "  metric_ep1_a_ii_3_year VARCHAR,\n",
    "  metric_ep1_a_ii_5_year VARCHAR,\n",
    "  trend_id INT NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (trend_id, country_name),\n",
    "  FOREIGN KEY (trend_id, country_name) REFERENCES assessment_trends(trend_id, country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL and populate data\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_trend_values_sql))\n",
    "    conn.commit()\n",
    "\n",
    "trend_values_df.to_sql(\"trend_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Trend values table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trend values table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load and clean the Excel file\n",
    "trend_values_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "trend_values_data.columns = trend_values_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Extract and rename relevant columns\n",
    "trend_values_df = trend_values_data[[\n",
    "    \"id\", \"country\", \"metric_ep1.a.i\", \"source_metric_ep1.a.i\", \"year_metric_ep1.a.i\",\n",
    "    \"metric_ep1.a.ii_1-year\", \"metric_ep1.a.ii_3-year\", \"metric_ep1.a.ii_5-year\"\n",
    "]].copy()\n",
    "\n",
    "# Rename to match lowercase column names in SQL\n",
    "trend_values_df.columns = [\n",
    "    \"trend_id\", \"country_name\", \"metric_ep1_a_i\", \"source_metric_ep1_a_i\", \"year_metric_ep1_a_i\",\n",
    "    \"metric_ep1_a_ii_1_year\", \"metric_ep1_a_ii_3_year\", \"metric_ep1_a_ii_5_year\"\n",
    "]\n",
    "\n",
    "# Convert year column to nullable integer\n",
    "trend_values_df[\"year_metric_ep1_a_i\"] = pd.to_numeric(trend_values_df[\"year_metric_ep1_a_i\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Drop and create the table with lowercase columns\n",
    "create_trend_values_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS trend_values;\n",
    "\n",
    "CREATE TABLE trend_values (\n",
    "  metric_ep1_a_i VARCHAR,\n",
    "  source_metric_ep1_a_i VARCHAR,\n",
    "  year_metric_ep1_a_i INT,\n",
    "  metric_ep1_a_ii_1_year VARCHAR,\n",
    "  metric_ep1_a_ii_3_year VARCHAR,\n",
    "  metric_ep1_a_ii_5_year VARCHAR,\n",
    "  trend_id INT NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (trend_id, country_name),\n",
    "  FOREIGN KEY (trend_id, country_name) REFERENCES assessment_trends(trend_id, country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute and populate the table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_trend_values_sql))\n",
    "    conn.commit()\n",
    "\n",
    "trend_values_df.to_sql(\"trend_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"✅ Trend values table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# values per year table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ value_per_year table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load and clean the Excel file\n",
    "trends_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "trends_data.columns = trends_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Identify year columns (2021 to 2030)\n",
    "year_cols = [col for col in trends_data.columns if col.isdigit() and 2021 <= int(col) <= 2030]\n",
    "\n",
    "# Reshape into long format\n",
    "value_per_year_df = trends_data[[\"id\", \"country\"] + year_cols].melt(\n",
    "    id_vars=[\"id\", \"country\"],\n",
    "    value_vars=year_cols,\n",
    "    var_name=\"year\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# Rename to match database schema\n",
    "value_per_year_df.columns = [\"trend_id\", \"country_name\", \"year\", \"value\"]\n",
    "value_per_year_df[\"year\"] = value_per_year_df[\"year\"].astype(int)\n",
    "value_per_year_df[\"value\"] = pd.to_numeric(value_per_year_df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with missing values (optional)\n",
    "value_per_year_df = value_per_year_df.dropna(subset=[\"value\"])\n",
    "\n",
    "# SQL to create the value_per_year table\n",
    "create_value_per_year_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS value_per_year;\n",
    "\n",
    "CREATE TABLE value_per_year (\n",
    "  year INT NOT NULL,\n",
    "  value FLOAT NOT NULL,\n",
    "  trend_id INT NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  FOREIGN KEY (trend_id, country_name) REFERENCES trend_values(trend_id, country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL and populate the table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_value_per_year_sql))\n",
    "    conn.commit()\n",
    "\n",
    "value_per_year_df.to_sql(\"value_per_year\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"✅ value_per_year table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
