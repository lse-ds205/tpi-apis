{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASCOR database creation \n",
    "\n",
    "This notebook creates the SQL database for the ASCOR data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import pandas as pd \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Add the project root to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Now import with full module path\n",
    "from utils.database_creation_utils import get_db_connection, get_engine\n",
    "\n",
    "engine = get_engine(db_name=\"ascor_api\")\n",
    "session = get_db_connection(db_name=\"ascor_api\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Country Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_countries.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop and create the country table\n",
    "create_country_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS country;\n",
    "\n",
    "CREATE TABLE country (\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  iso VARCHAR,\n",
    "  region VARCHAR,\n",
    "  bank_lending_group VARCHAR,\n",
    "  imf_category VARCHAR,\n",
    "  un_party_type VARCHAR,\n",
    "  PRIMARY KEY (country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_country_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Select and rename columns to match database schema\n",
    "country_df = df[[\n",
    "    'Name',\n",
    "    'Country ISO code',\n",
    "    'Region',\n",
    "    'World Bank lending group',\n",
    "    'International Monetary Fund fiscal monitor category',\n",
    "    'Type of Party to the United Nations Framework Convention on Climate Change'\n",
    "]].copy()\n",
    "\n",
    "country_df.columns = [\n",
    "    'country_name', 'iso', 'region',\n",
    "    'bank_lending_group', 'imf_category', 'un_party_type'\n",
    "]\n",
    "\n",
    "# Insert into database\n",
    "country_df.to_sql(\"country\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Country table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Benchmark Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark tables created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_benchmarks.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Drop and create the benchmark tables\n",
    "create_benchmark_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS benchmark_values;\n",
    "DROP TABLE IF EXISTS benchmarks;\n",
    "\n",
    "CREATE TABLE benchmarks (\n",
    "  benchmark_id INT NOT NULL,\n",
    "  publication_date DATE NOT NULL,\n",
    "  emissions_metric VARCHAR NOT NULL,\n",
    "  emissions_boundary VARCHAR NOT NULL,\n",
    "  units VARCHAR NOT NULL,\n",
    "  benchmark_type VARCHAR NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (benchmark_id),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\n",
    "CREATE TABLE benchmark_values (\n",
    "  value FLOAT NOT NULL,\n",
    "  year INT NOT NULL,\n",
    "  benchmark_id INT NOT NULL,\n",
    "  PRIMARY KEY (benchmark_id, year),\n",
    "  FOREIGN KEY (benchmark_id) REFERENCES benchmarks(benchmark_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_benchmark_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Prepare the `benchmarks` DataFrame\n",
    "benchmarks_df = df[[\n",
    "    \"id\", \"publication_date\", \"emissions_metric\", \"emissions_boundary\",\n",
    "    \"units\", \"benchmark_type\", \"country\"\n",
    "]].copy()\n",
    "\n",
    "benchmarks_df.columns = [\n",
    "    \"benchmark_id\", \"publication_date\", \"emissions_metric\", \"emissions_boundary\",\n",
    "    \"units\", \"benchmark_type\", \"country_name\"\n",
    "]\n",
    "\n",
    "# Prepare the `benchmark_values` DataFrame\n",
    "value_columns = [col for col in df.columns if col.isdigit()]\n",
    "benchmark_values_df = df[['id'] + value_columns].melt(\n",
    "    id_vars='id',\n",
    "    var_name='year',\n",
    "    value_name='value'\n",
    ").dropna()\n",
    "\n",
    "benchmark_values_df.columns = ['benchmark_id', 'year', 'value']\n",
    "benchmark_values_df['year'] = benchmark_values_df['year'].astype(int)\n",
    "\n",
    "# Insert into the database\n",
    "benchmarks_df.to_sql(\"benchmarks\", engine, if_exists=\"append\", index=False)\n",
    "benchmark_values_df.to_sql(\"benchmark_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Benchmark tables created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment elements table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_indicators.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Select and rename columns to match database schema\n",
    "assessment_elements_df = df[[\n",
    "    'code', 'text', 'units_or_response_type', 'type'\n",
    "]].copy()\n",
    "\n",
    "assessment_elements_df.columns = ['code', 'text', 'response_type', 'type']\n",
    "assessment_elements_df['response_type'] = assessment_elements_df['response_type'].fillna(\"Not specified\")\n",
    "\n",
    "# Drop and create the assessment_elements table\n",
    "create_assessment_elements_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_elements;\n",
    "\n",
    "CREATE TABLE assessment_elements (\n",
    "  code VARCHAR NOT NULL,\n",
    "  text VARCHAR NOTL NUL,\n",
    "  response_type VARCHAR NOT NULL,\n",
    "  type VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (code)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_elements_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Insert into the database\n",
    "assessment_elements_df.to_sql(\"assessment_elements\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment elements table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Results Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/fkxp7dk132s2dqm5fccfhy9h0000gn/T/ipykernel_49747/1993979402.py:44: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  assessment_date = pd.to_datetime(row[\"Assessment date\"]).date()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment results table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the assessment results Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop and create the assessment_results table\n",
    "create_assessment_results_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_results;\n",
    "\n",
    "CREATE TABLE assessment_results (\n",
    "  assessment_id INT NOT NULL,\n",
    "  response VARCHAR,\n",
    "  assessment_date DATE,\n",
    "  publication_date DATE,\n",
    "  source VARCHAR,\n",
    "  year VARCHAR,\n",
    "  code VARCHAR NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (assessment_id, code),\n",
    "  FOREIGN KEY (code) REFERENCES assessment_elements(code),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_results_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Columns that represent coded responses (non-pillar only)\n",
    "response_cols = [col for col in df.columns if (\n",
    "    col.startswith(\"indicator \") or\n",
    "    col.startswith(\"metric \") or\n",
    "    col.startswith(\"area \")\n",
    ")]\n",
    "\n",
    "# Prepare a list for parsed results\n",
    "rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    assessment_id = row[\"Id\"]\n",
    "    country_name = row[\"Country\"]\n",
    "    assessment_date = pd.to_datetime(row[\"Assessment date\"]).date()\n",
    "    publication_date = pd.to_datetime(row[\"Publication date\"]).date()\n",
    "\n",
    "    for col in response_cols:\n",
    "        code = col.split(\" \", 1)[1]  # Extract e.g., \"EP.1.a\"\n",
    "        response = row[col] if pd.notna(row[col]) else None\n",
    "        original_col = col  # e.g., 'indicator EP.1.a'\n",
    "\n",
    "        # Look for optional year and source columns\n",
    "        year_col = f\"year {original_col}\"\n",
    "        year = str(int(row[year_col])) if year_col in df.columns and pd.notna(row[year_col]) else None\n",
    "\n",
    "        source_col = f\"source {original_col}\"\n",
    "        source = row[source_col] if source_col in df.columns and pd.notna(row[source_col]) else None\n",
    "\n",
    "        rows.append({\n",
    "            \"assessment_id\": assessment_id,\n",
    "            \"response\": response,\n",
    "            \"assessment_date\": assessment_date,\n",
    "            \"publication_date\": publication_date,\n",
    "            \"source\": source,\n",
    "            \"year\": year,\n",
    "            \"code\": code,\n",
    "            \"country_name\": country_name\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "assessment_results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Insert into the database\n",
    "assessment_results_df.to_sql(\"assessment_results\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment results table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Trends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment trends table created and populated successfully with composite primary key.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/fkxp7dk132s2dqm5fccfhy9h0000gn/T/ipykernel_49747/1832612965.py:20: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  assessment_trends_df[\"assessment_date\"] = pd.to_datetime(assessment_trends_df[\"assessment_date\"]).dt.date\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Select and rename relevant columns\n",
    "assessment_trends_df = df[[\n",
    "    'id', 'country', 'emissions_metric', 'emissions_boundary',\n",
    "    'units', 'assessment_date', 'publication_date', 'last_historical_year'\n",
    "]].copy()\n",
    "\n",
    "assessment_trends_df.columns = [\n",
    "    'trend_id', 'country_name', 'emissions_metric', 'emissions_boundary',\n",
    "    'units', 'assessment_date', 'publication_date', 'last_historical_year'\n",
    "]\n",
    "\n",
    "# Convert date and year fields to appropriate types\n",
    "assessment_trends_df[\"assessment_date\"] = pd.to_datetime(assessment_trends_df[\"assessment_date\"]).dt.date\n",
    "assessment_trends_df[\"publication_date\"] = pd.to_datetime(assessment_trends_df[\"publication_date\"]).dt.date\n",
    "assessment_trends_df[\"last_historical_year\"] = assessment_trends_df[\"last_historical_year\"].astype(\"Int64\")\n",
    "\n",
    "# SQL schema with composite primary key\n",
    "create_assessment_trends_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS assessment_trends;\n",
    "\n",
    "CREATE TABLE assessment_trends (\n",
    "  trend_id INT NOT NULL,\n",
    "  emissions_metric VARCHAR,\n",
    "  emissions_boundary VARCHAR,\n",
    "  units VARCHAR,\n",
    "  assessment_date DATE,\n",
    "  publication_date DATE,\n",
    "  last_historical_year INT,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (trend_id, country_name),\n",
    "  FOREIGN KEY (country_name) REFERENCES country(country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL and insert the data\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_assessment_trends_sql))\n",
    "    conn.commit()\n",
    "\n",
    "assessment_trends_df.to_sql(\"assessment_trends\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Assessment trends table created and populated successfully with composite primary key.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend values table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i think the commeneted out bit is redundent but keeping just in case need in future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trend values table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import text\n",
    "\n",
    "# # Load and clean the Excel file\n",
    "# trend_values_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "# trend_values_data.columns = trend_values_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# # Extract and rename relevant columns\n",
    "# trend_values_df = trend_values_data[[\n",
    "#     \"id\", \"country\", \"metric_ep1.a.i\", \"source_metric_ep1.a.i\", \"year_metric_ep1.a.i\",\n",
    "#     \"metric_ep1.a.ii_1-year\", \"metric_ep1.a.ii_3-year\", \"metric_ep1.a.ii_5-year\"\n",
    "# ]].copy()\n",
    "\n",
    "# # Rename to match lowercase column names in SQL\n",
    "# trend_values_df.columns = [\n",
    "#     \"trend_id\", \"country_name\", \"metric_ep1_a_i\", \"source_metric_ep1_a_i\", \"year_metric_ep1_a_i\",\n",
    "#     \"metric_ep1_a_ii_1_year\", \"metric_ep1_a_ii_3_year\", \"metric_ep1_a_ii_5_year\"\n",
    "# ]\n",
    "\n",
    "# # Convert year column to nullable integer\n",
    "# trend_values_df[\"year_metric_ep1_a_i\"] = pd.to_numeric(trend_values_df[\"year_metric_ep1_a_i\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# # Drop and create the table with lowercase columns\n",
    "# create_trend_values_sql = \"\"\"\n",
    "# DROP TABLE IF EXISTS trend_values;\n",
    "\n",
    "# CREATE TABLE trend_values (\n",
    "#   metric_ep1_a_i VARCHAR,\n",
    "#   source_metric_ep1_a_i VARCHAR,\n",
    "#   year_metric_ep1_a_i INT,\n",
    "#   metric_ep1_a_ii_1_year VARCHAR,\n",
    "#   metric_ep1_a_ii_3_year VARCHAR,\n",
    "#   metric_ep1_a_ii_5_year VARCHAR,\n",
    "#   trend_id INT NOT NULL,\n",
    "#   country_name VARCHAR NOT NULL,\n",
    "#   PRIMARY KEY (trend_id, country_name),\n",
    "#   FOREIGN KEY (trend_id, country_name) REFERENCES assessment_trends(trend_id, country_name)\n",
    "# );\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute and populate the table\n",
    "# with engine.connect() as conn:\n",
    "#     conn.execute(text(create_trend_values_sql))\n",
    "#     conn.commit()\n",
    "\n",
    "# trend_values_df.to_sql(\"trend_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# print(\"✅ Trend values table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned trend_values table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load and clean the Excel file\n",
    "trend_values_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "trend_values_data.columns = trend_values_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Extract relevant columns\n",
    "trend_values_df = trend_values_data[[\n",
    "    \"id\", \"country\", \"metric_ep1.a.i\", \"source_metric_ep1.a.i\", \"year_metric_ep1.a.i\",\n",
    "    \"metric_ep1.a.ii_1-year\", \"metric_ep1.a.ii_3-year\", \"metric_ep1.a.ii_5-year\"\n",
    "]].copy()\n",
    "\n",
    "# Rename for SQL compatibility\n",
    "trend_values_df.columns = [\n",
    "    \"trend_id\", \"country_name\", \"metric_ep1_a_i\", \"source_metric_ep1_a_i\", \"year_metric_ep1_a_i\",\n",
    "    \"metric_ep1_a_ii_1_year\", \"metric_ep1_a_ii_3_year\", \"metric_ep1_a_ii_5_year\"\n",
    "]\n",
    "\n",
    "# Clean `metric_ep1_a_i`: set to NaN if \"No data\" or not numeric, then convert to float\n",
    "trend_values_df[\"metric_ep1_a_i\"] = pd.to_numeric(\n",
    "    trend_values_df[\"metric_ep1_a_i\"].replace(\"No data\", pd.NA), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Clean `year_metric_ep1_a_i` to integer\n",
    "trend_values_df[\"year_metric_ep1_a_i\"] = pd.to_numeric(\n",
    "    trend_values_df[\"year_metric_ep1_a_i\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# Optionally strip % from change columns (they will remain as strings or can be converted)\n",
    "for col in [\"metric_ep1_a_ii_1_year\", \"metric_ep1_a_ii_3_year\", \"metric_ep1_a_ii_5_year\"]:\n",
    "    trend_values_df[col] = trend_values_df[col].astype(str).str.replace(\"%\", \"\").str.strip()\n",
    "    trend_values_df[col] = trend_values_df[col].replace(\"Not applicable\", pd.NA)\n",
    "\n",
    "# Create the SQL table\n",
    "create_trend_values_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS trend_values;\n",
    "\n",
    "CREATE TABLE trend_values (\n",
    "  metric_ep1_a_i FLOAT,\n",
    "  source_metric_ep1_a_i VARCHAR,\n",
    "  year_metric_ep1_a_i INT,\n",
    "  metric_ep1_a_ii_1_year VARCHAR,\n",
    "  metric_ep1_a_ii_3_year VARCHAR,\n",
    "  metric_ep1_a_ii_5_year VARCHAR,\n",
    "  trend_id INT NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  PRIMARY KEY (trend_id, country_name),\n",
    "  FOREIGN KEY (trend_id, country_name) REFERENCES assessment_trends(trend_id, country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute table creation\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_trend_values_sql))\n",
    "    conn.commit()\n",
    "\n",
    "# Insert cleaned data\n",
    "trend_values_df.to_sql(\"trend_values\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"✅ Cleaned trend_values table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# values per year table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ value_per_year table created and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Load and clean the Excel file\n",
    "trends_data = pd.read_excel(\"../data/TPI_ASCOR_data_13012025/ASCOR_assessments_results_trends_pathways.xlsx\")\n",
    "trends_data.columns = trends_data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Identify year columns (2021 to 2030)\n",
    "year_cols = [col for col in trends_data.columns if col.isdigit() and 2021 <= int(col) <= 2030]\n",
    "\n",
    "# Reshape into long format\n",
    "value_per_year_df = trends_data[[\"id\", \"country\"] + year_cols].melt(\n",
    "    id_vars=[\"id\", \"country\"],\n",
    "    value_vars=year_cols,\n",
    "    var_name=\"year\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# Rename to match database schema\n",
    "value_per_year_df.columns = [\"trend_id\", \"country_name\", \"year\", \"value\"]\n",
    "value_per_year_df[\"year\"] = value_per_year_df[\"year\"].astype(int)\n",
    "value_per_year_df[\"value\"] = pd.to_numeric(value_per_year_df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with missing values (optional)\n",
    "value_per_year_df = value_per_year_df.dropna(subset=[\"value\"])\n",
    "\n",
    "# SQL to create the value_per_year table\n",
    "create_value_per_year_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS value_per_year;\n",
    "\n",
    "CREATE TABLE value_per_year (\n",
    "  year INT NOT NULL,\n",
    "  value FLOAT NOT NULL,\n",
    "  trend_id INT NOT NULL,\n",
    "  country_name VARCHAR NOT NULL,\n",
    "  FOREIGN KEY (trend_id, country_name) REFERENCES trend_values(trend_id, country_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL and populate the table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_value_per_year_sql))\n",
    "    conn.commit()\n",
    "\n",
    "value_per_year_df.to_sql(\"value_per_year\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"✅ value_per_year table created and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
